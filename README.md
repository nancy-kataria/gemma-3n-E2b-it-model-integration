# Gemma-3n-E4b-it Model Integration

Gemma-3n is a lightweight model designed to work locally on your system without the internet conneection. 

## Goal
Running the model using python and hugging face transformers.

## How to use the model

1. Create a virtual environment.
 ```
 python -m venv .venv
 ```
2. Activate the virtual environment.
```
.venv\Scripts\Activate.ps1
```
3. Install the requirements.
```
pip install -r requirements.txt
```
4. Get access to the gated model on hugging face.
5. Get an access hf token. 
6. Download the model locally from hugging face.
7. Use the model path for your pipeline.
8. Change the device according to your personal system.
9. Run the model.
```
python image-text-to-text.py
```

